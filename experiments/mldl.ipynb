{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primary Admissions information\n",
    "# Add'.gz' if you uploaded .gz file\n",
    "df = pd.read_csv('../MIMIC/physionet.org/files/mimiciii/1.4/ADMISSIONS.csv')\n",
    "# df = pd.read_csv('ADMISSIONS.csv.gz')\n",
    "\n",
    "# Patient specific info such as gender\n",
    "df_pat = pd.read_csv('../MIMIC/physionet.org/files/mimiciii/1.4/PATIENTS.csv')\n",
    "\n",
    "# Diagnosis for each admission to hospital\n",
    "df_diagcode = pd.read_csv('../MIMIC/physionet.org/files/mimiciii/1.4/DIAGNOSES_ICD.csv')\n",
    "\n",
    "# Intensive Care Unit (ICU) for each admission to hospital\n",
    "df_icu = pd.read_csv('../MIMIC/physionet.org/files/mimiciii/1.4/ICUSTAYS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert admission and discharge times to datatime type\n",
    "df['ADMITTIME'] = pd.to_datetime(df['ADMITTIME'])\n",
    "df['DISCHTIME'] = pd.to_datetime(df['DISCHTIME'])\n",
    "\n",
    "# Convert timedelta type into float 'days', 86400 seconds in a day\n",
    "df['LOS'] = (df['DISCHTIME'] - df['ADMITTIME']).dt.total_seconds()/86400\n",
    "\n",
    "# Drop LOS < 0\n",
    "df = df[df['LOS'] > 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Mark admissions where patients died in boolean column\n",
    "df['DECEASED'] = df['DEATHTIME'].notnull().map({True:1, False:0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_75961/1325925633.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['ETHNICITY'].replace(regex=r'^ASIAN\\D*', value='ASIAN', inplace=True)\n",
      "/tmp/ipykernel_75961/1325925633.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['ETHNICITY'].replace(regex=r'^WHITE\\D*', value='WHITE', inplace=True)\n",
      "/tmp/ipykernel_75961/1325925633.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['ETHNICITY'].replace(regex=r'^HISPANIC\\D*', value='HISPANIC/LATINO', inplace=True)\n",
      "/tmp/ipykernel_75961/1325925633.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['ETHNICITY'].replace(regex=r'^BLACK\\D*', value='BLACK/AFRICAN AMERICAN', inplace=True)\n",
      "/tmp/ipykernel_75961/1325925633.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['ETHNICITY'].replace(['UNABLE TO OBTAIN', 'OTHER', 'PATIENT DECLINED TO ANSWER',\n",
      "/tmp/ipykernel_75961/1325925633.py:8: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df['ETHNICITY'].loc[~df['ETHNICITY'].isin(df['ETHNICITY'].value_counts().nlargest(5).index.tolist())] = 'OTHER/UNKNOWN'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ETHNICITY\n",
       "WHITE                     41268\n",
       "OTHER/UNKNOWN              7700\n",
       "BLACK/AFRICAN AMERICAN     5779\n",
       "HISPANIC/LATINO            2125\n",
       "ASIAN                      2006\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compress the number of ethnicity categories\n",
    "df['ETHNICITY'].replace(regex=r'^ASIAN\\D*', value='ASIAN', inplace=True)\n",
    "df['ETHNICITY'].replace(regex=r'^WHITE\\D*', value='WHITE', inplace=True)\n",
    "df['ETHNICITY'].replace(regex=r'^HISPANIC\\D*', value='HISPANIC/LATINO', inplace=True)\n",
    "df['ETHNICITY'].replace(regex=r'^BLACK\\D*', value='BLACK/AFRICAN AMERICAN', inplace=True)\n",
    "df['ETHNICITY'].replace(['UNABLE TO OBTAIN', 'OTHER', 'PATIENT DECLINED TO ANSWER',\n",
    "                         'UNKNOWN/NOT SPECIFIED'], value='OTHER/UNKNOWN', inplace=True)\n",
    "df['ETHNICITY'].loc[~df['ETHNICITY'].isin(df['ETHNICITY'].value_counts().nlargest(5).index.tolist())] = 'OTHER/UNKNOWN'\n",
    "df['ETHNICITY'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RELIGION\n",
      "RELIGIOUS        38898\n",
      "NOT SPECIFIED    11738\n",
      "UNOBTAINABLE      8242\n",
      "Name: count, dtype: int64\n",
      "0.6606542341791501\n",
      "0.1993613913516084\n",
      "0.13998437446924147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_75961/2507947393.py:3: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df['RELIGION'].loc[~df['RELIGION'].isin(['NOT SPECIFIED', 'UNOBTAINABLE'])] = 'RELIGIOUS'\n",
      "/tmp/ipykernel_75961/2507947393.py:6: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  print(df['RELIGION'].value_counts()[0]/len(df['RELIGION']))\n",
      "/tmp/ipykernel_75961/2507947393.py:7: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  print(df['RELIGION'].value_counts()[1]/len(df['RELIGION']))\n",
      "/tmp/ipykernel_75961/2507947393.py:8: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  print(df['RELIGION'].value_counts()[2]/len(df['RELIGION']))\n"
     ]
    }
   ],
   "source": [
    "# Reduce categories to terms of religious or not\n",
    "# I tested with and without category reduction, with little change in R2 score\n",
    "df['RELIGION'].loc[~df['RELIGION'].isin(['NOT SPECIFIED', 'UNOBTAINABLE'])] = 'RELIGIOUS'\n",
    "\n",
    "print(df['RELIGION'].value_counts())\n",
    "print(df['RELIGION'].value_counts()[0]/len(df['RELIGION']))\n",
    "print(df['RELIGION'].value_counts()[1]/len(df['RELIGION']))\n",
    "print(df['RELIGION'].value_counts()[2]/len(df['RELIGION']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MARITAL_STATUS\n",
       "MARRIED              24199\n",
       "SINGLE               13238\n",
       "UNKNOWN (DEFAULT)    10440\n",
       "WIDOWED               7204\n",
       "DIVORCED              3211\n",
       "SEPARATED              571\n",
       "LIFE PARTNER            15\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fix NaNs and file under 'UNKNOWN'\n",
    "df['MARITAL_STATUS'] = df['MARITAL_STATUS'].fillna('UNKNOWN (DEFAULT)')\n",
    "df['MARITAL_STATUS'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_75961/1751215599.py:3: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_diagcode['recode'] = df_diagcode['recode'][~df_diagcode['recode'].str.contains(\"[a-zA-Z]\").fillna(False)]\n",
      "/tmp/ipykernel_75961/1751215599.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_diagcode['recode'].fillna(value='999', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Filter out E and V codes since processing will be done on the numeric first 3 values\n",
    "df_diagcode['recode'] = df_diagcode['ICD9_CODE']\n",
    "df_diagcode['recode'] = df_diagcode['recode'][~df_diagcode['recode'].str.contains(\"[a-zA-Z]\").fillna(False)]\n",
    "df_diagcode['recode'].fillna(value='999', inplace=True)\n",
    "df_diagcode['recode'] = df_diagcode['recode'].str.slice(start=0, stop=3, step=1)\n",
    "df_diagcode['recode'] = df_diagcode['recode'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ICD-9 Main Category ranges\n",
    "icd9_ranges = [(1, 140), (140, 240), (240, 280), (280, 290), (290, 320), (320, 390),\n",
    "               (390, 460), (460, 520), (520, 580), (580, 630), (630, 680), (680, 710),\n",
    "               (710, 740), (740, 760), (760, 780), (780, 800), (800, 1000), (1000, 2000)]\n",
    "\n",
    "# Associated category names\n",
    "diag_dict = {0: 'infectious', 1: 'neoplasms', 2: 'endocrine', 3: 'blood',\n",
    "             4: 'mental', 5: 'nervous', 6: 'circulatory', 7: 'respiratory',\n",
    "             8: 'digestive', 9: 'genitourinary', 10: 'pregnancy', 11: 'skin',\n",
    "             12: 'muscular', 13: 'congenital', 14: 'prenatal', 15: 'misc',\n",
    "             16: 'injury', 17: 'misc'}\n",
    "\n",
    "# Re-code in terms of integer\n",
    "for num, cat_range in enumerate(icd9_ranges):\n",
    "    df_diagcode['recode'] = np.where(df_diagcode['recode'].between(cat_range[0],cat_range[1]),\n",
    "            num, df_diagcode['recode'])\n",
    "\n",
    "# Convert integer to category name using diag_dict\n",
    "df_diagcode['recode'] = df_diagcode['recode']\n",
    "df_diagcode['cat'] = df_diagcode['recode'].replace(diag_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_75961/384778453.py:3: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_diagcode['recode'] = df_diagcode['recode'][~df_diagcode['recode'].str.contains(\"[a-zA-Z]\").fillna(False)]\n",
      "/tmp/ipykernel_75961/384778453.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_diagcode['recode'].fillna(value='999', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ROW_ID  SUBJECT_ID  HADM_ID  SEQ_NUM ICD9_CODE  recode            cat\n",
      "0    1297         109   172335      1.0     40301       6    circulatory\n",
      "1    1298         109   172335      2.0       486       7    respiratory\n",
      "2    1299         109   172335      3.0     58281       9  genitourinary\n",
      "3    1300         109   172335      4.0      5855       9  genitourinary\n",
      "4    1301         109   172335      5.0      4254       6    circulatory\n"
     ]
    }
   ],
   "source": [
    "# Filter out E and V codes since processing will be done on the numeric first 3 values\n",
    "df_diagcode['recode'] = df_diagcode['ICD9_CODE']\n",
    "df_diagcode['recode'] = df_diagcode['recode'][~df_diagcode['recode'].str.contains(\"[a-zA-Z]\").fillna(False)]\n",
    "df_diagcode['recode'].fillna(value='999', inplace=True)\n",
    "df_diagcode['recode'] = df_diagcode['recode'].str.slice(start=0, stop=3, step=1)\n",
    "df_diagcode['recode'] = df_diagcode['recode'].astype(int)\n",
    "\n",
    "# ICD-9 Main Category ranges\n",
    "icd9_ranges = [(1, 140), (140, 240), (240, 280), (280, 290), (290, 320), (320, 390),\n",
    "               (390, 460), (460, 520), (520, 580), (580, 630), (630, 680), (680, 710),\n",
    "               (710, 740), (740, 760), (760, 780), (780, 800), (800, 1000), (1000, 2000)]\n",
    "\n",
    "# Associated category names\n",
    "diag_dict = {0: 'infectious', 1: 'neoplasms', 2: 'endocrine', 3: 'blood',\n",
    "             4: 'mental', 5: 'nervous', 6: 'circulatory', 7: 'respiratory',\n",
    "             8: 'digestive', 9: 'genitourinary', 10: 'pregnancy', 11: 'skin',\n",
    "             12: 'muscular', 13: 'congenital', 14: 'prenatal', 15: 'misc',\n",
    "             16: 'injury', 17: 'misc'}\n",
    "\n",
    "# Re-code in terms of integer\n",
    "for num, cat_range in enumerate(icd9_ranges):\n",
    "    df_diagcode['recode'] = np.where(df_diagcode['recode'].between(cat_range[0], cat_range[1]),\n",
    "                                     num, df_diagcode['recode'])\n",
    "\n",
    "# Convert integer to category name using diag_dict\n",
    "df_diagcode['recode'] = df_diagcode['recode']\n",
    "df_diagcode['cat'] = df_diagcode['recode'].replace(diag_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of diagnoses for each admission\n",
    "hadm_list = df_diagcode.groupby('HADM_ID')['cat'].apply(list).reset_index()\n",
    "hadm_item = pd.get_dummies(hadm_list['cat'].apply(pd.Series).stack()).groupby(level=0).sum()\n",
    "hadm_item = hadm_item.join(hadm_list['HADM_ID'], how=\"outer\")\n",
    "df = df.merge(hadm_item, how='inner', on='HADM_ID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROW_ID</th>\n",
       "      <th>DISCHTIME</th>\n",
       "      <th>ADMISSION_TYPE</th>\n",
       "      <th>INSURANCE</th>\n",
       "      <th>RELIGION</th>\n",
       "      <th>MARITAL_STATUS</th>\n",
       "      <th>ETHNICITY</th>\n",
       "      <th>EDREGTIME</th>\n",
       "      <th>EDOUTTIME</th>\n",
       "      <th>HOSPITAL_EXPIRE_FLAG</th>\n",
       "      <th>...</th>\n",
       "      <th>neoplasms</th>\n",
       "      <th>nervous</th>\n",
       "      <th>pregnancy</th>\n",
       "      <th>prenatal</th>\n",
       "      <th>respiratory</th>\n",
       "      <th>skin</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>age</th>\n",
       "      <th>ICU</th>\n",
       "      <th>NICU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45749.0</td>\n",
       "      <td>2117-09-17 16:45:00</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>Private</td>\n",
       "      <td>RELIGIOUS</td>\n",
       "      <td>DIVORCED</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>2117-09-11 08:59:00</td>\n",
       "      <td>2117-09-11 12:35:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>young_adult</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44463.0</td>\n",
       "      <td>2150-04-21 17:30:00</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>Private</td>\n",
       "      <td>NOT SPECIFIED</td>\n",
       "      <td>SINGLE</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>2150-04-17 13:10:00</td>\n",
       "      <td>2150-04-17 17:47:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>senior</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12108.0</td>\n",
       "      <td>2108-04-18 17:18:00</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>Private</td>\n",
       "      <td>NOT SPECIFIED</td>\n",
       "      <td>SINGLE</td>\n",
       "      <td>BLACK/AFRICAN AMERICAN</td>\n",
       "      <td>2108-04-06 11:39:00</td>\n",
       "      <td>2108-04-06 17:56:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>middle_adult</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28086.0</td>\n",
       "      <td>2145-04-07 12:40:00</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>Private</td>\n",
       "      <td>RELIGIOUS</td>\n",
       "      <td>MARRIED</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>2145-03-30 20:43:00</td>\n",
       "      <td>2145-03-31 06:08:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>senior</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>671.0</td>\n",
       "      <td>2162-05-21 13:37:00</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>Private</td>\n",
       "      <td>RELIGIOUS</td>\n",
       "      <td>MARRIED</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>senior</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ROW_ID           DISCHTIME ADMISSION_TYPE INSURANCE       RELIGION  \\\n",
       "0  45749.0 2117-09-17 16:45:00      EMERGENCY   Private      RELIGIOUS   \n",
       "1  44463.0 2150-04-21 17:30:00      EMERGENCY   Private  NOT SPECIFIED   \n",
       "2  12108.0 2108-04-18 17:18:00      EMERGENCY   Private  NOT SPECIFIED   \n",
       "3  28086.0 2145-04-07 12:40:00      EMERGENCY   Private      RELIGIOUS   \n",
       "4    671.0 2162-05-21 13:37:00      EMERGENCY   Private      RELIGIOUS   \n",
       "\n",
       "  MARITAL_STATUS               ETHNICITY            EDREGTIME  \\\n",
       "0       DIVORCED                   WHITE  2117-09-11 08:59:00   \n",
       "1         SINGLE                   WHITE  2150-04-17 13:10:00   \n",
       "2         SINGLE  BLACK/AFRICAN AMERICAN  2108-04-06 11:39:00   \n",
       "3        MARRIED                   WHITE  2145-03-30 20:43:00   \n",
       "4        MARRIED                   WHITE                  NaN   \n",
       "\n",
       "             EDOUTTIME  HOSPITAL_EXPIRE_FLAG  ...  neoplasms  nervous  \\\n",
       "0  2117-09-11 12:35:00                   0.0  ...        0.0      2.0   \n",
       "1  2150-04-17 17:47:00                   0.0  ...        0.0      0.0   \n",
       "2  2108-04-06 17:56:00                   0.0  ...        1.0      0.0   \n",
       "3  2145-03-31 06:08:00                   0.0  ...        0.0      0.0   \n",
       "4                  NaN                   0.0  ...        0.0      0.0   \n",
       "\n",
       "   pregnancy  prenatal  respiratory  skin  GENDER           age  ICU  NICU  \n",
       "0        0.0       0.0          0.0   1.0     1.0   young_adult  1.0   0.0  \n",
       "1        0.0       0.0          0.0   0.0     0.0        senior  1.0   0.0  \n",
       "2        0.0       0.0          3.0   0.0     1.0  middle_adult  1.0   0.0  \n",
       "3        0.0       0.0          1.0   0.0     1.0        senior  1.0   0.0  \n",
       "4        0.0       0.0          0.0   0.0     0.0        senior  1.0   0.0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pat = pd.read_csv('../MIMIC/physionet.org/files/mimiciii/1.4/PATIENTS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pat['DOB'] = pd.to_datetime(df_pat['DOB'])\n",
    "df_pat = df_pat[['SUBJECT_ID', 'DOB', 'GENDER']]\n",
    "df = df.merge(df_pat, how='inner', on='SUBJECT_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_age_min = df[['SUBJECT_ID', 'ADMITTIME']].groupby('SUBJECT_ID').min().reset_index()\n",
    "df_age_min.columns = ['SUBJECT_ID', 'ADMIT_MIN']\n",
    "df = df.merge(df_age_min, how='outer', on='SUBJECT_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ADMIT_MIN'] = pd.to_datetime(df['ADMIT_MIN']).dt.date\n",
    "df['DOB'] = pd.to_datetime(df['DOB']).dt.date\n",
    "df['age'] = df.apply(lambda e: (e['ADMIT_MIN'] - e['DOB']).days/365, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_ranges = [(0, 13), (13, 36), (36, 56), (56, 100)]\n",
    "for num, cat_range in enumerate(age_ranges):\n",
    "    df['age'] = np.where(df['age'].between(cat_range[0],cat_range[1]),\n",
    "            num, df['age'])\n",
    "\n",
    "age_dict = {0: 'newborn', 1: 'young_adult', 2: 'middle_adult', 3: 'senior'}\n",
    "df['age'] = df['age'].replace(age_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_75961/1715981341.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['GENDER'].replace({'M': 0, 'F':1}, inplace=True)\n",
      "/tmp/ipykernel_75961/1715981341.py:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['GENDER'].replace({'M': 0, 'F':1}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df['GENDER'].replace({'M': 0, 'F':1}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_icu = pd.read_csv('../MIMIC/physionet.org/files/mimiciii/1.4/ICUSTAYS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_75961/2533366671.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_icu['FIRST_CAREUNIT'].replace({'CCU': 'ICU', 'CSRU': 'ICU', 'MICU': 'ICU',\n"
     ]
    }
   ],
   "source": [
    "df_icu['FIRST_CAREUNIT'].replace({'CCU': 'ICU', 'CSRU': 'ICU', 'MICU': 'ICU',\n",
    "                                  'SICU': 'ICU', 'TSICU': 'ICU'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_icu['cat'] = df_icu['FIRST_CAREUNIT']\n",
    "icu_list = df_icu.groupby('HADM_ID')['cat'].apply(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create admission-ICU matrix\n",
    "icu_item = pd.get_dummies(icu_list['cat'].apply(pd.Series).stack()).groupby(level=0).sum()\n",
    "icu_item[icu_item >= 1] = 1\n",
    "icu_item = icu_item.join(icu_list['HADM_ID'], how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(icu_item, how='outer', on='HADM_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_75961/2137612640.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['ICU'].fillna(value=0, inplace=True)\n",
      "/tmp/ipykernel_75961/2137612640.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['NICU'].fillna(value=0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df['ICU'].fillna(value=0, inplace=True)\n",
    "df['NICU'].fillna(value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove deceased persons as they will skew LOS result\n",
    "df = df[df['DECEASED'] == 0]\n",
    "\n",
    "# Remove LOS with negative number, likely entry form error\n",
    "df = df[df['LOS'] > 0]\n",
    "\n",
    "# Drop unused or no longer needed columns\n",
    "df.drop(columns=['SUBJECT_ID', 'HADM_ID', 'ADMITTIME', 'ADMISSION_LOCATION',\n",
    "                'DISCHARGE_LOCATION', 'LANGUAGE', 'ADMIT_MIN', 'DOB',\n",
    "                'DIAGNOSIS', 'DECEASED',  'DEATHTIME'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target Variable (Length-of-Stay)\n",
    "LOS = df['LOS'].values\n",
    "# Prediction Features\n",
    "features = df.drop(columns=['LOS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 53104 entries, 0 to 58961\n",
      "Data columns (total 32 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   ROW_ID                53104 non-null  float64       \n",
      " 1   DISCHTIME             53104 non-null  datetime64[ns]\n",
      " 2   ADMISSION_TYPE        53104 non-null  object        \n",
      " 3   INSURANCE             53104 non-null  object        \n",
      " 4   RELIGION              53104 non-null  object        \n",
      " 5   MARITAL_STATUS        53104 non-null  object        \n",
      " 6   ETHNICITY             53104 non-null  object        \n",
      " 7   EDREGTIME             26783 non-null  object        \n",
      " 8   EDOUTTIME             26783 non-null  object        \n",
      " 9   HOSPITAL_EXPIRE_FLAG  53104 non-null  float64       \n",
      " 10  HAS_CHARTEVENTS_DATA  53104 non-null  float64       \n",
      " 11  blood                 53104 non-null  float64       \n",
      " 12  circulatory           53104 non-null  float64       \n",
      " 13  congenital            53104 non-null  float64       \n",
      " 14  digestive             53104 non-null  float64       \n",
      " 15  endocrine             53104 non-null  float64       \n",
      " 16  genitourinary         53104 non-null  float64       \n",
      " 17  infectious            53104 non-null  float64       \n",
      " 18  injury                53104 non-null  float64       \n",
      " 19  mental                53104 non-null  float64       \n",
      " 20  misc                  53104 non-null  float64       \n",
      " 21  muscular              53104 non-null  float64       \n",
      " 22  neoplasms             53104 non-null  float64       \n",
      " 23  nervous               53104 non-null  float64       \n",
      " 24  pregnancy             53104 non-null  float64       \n",
      " 25  prenatal              53104 non-null  float64       \n",
      " 26  respiratory           53104 non-null  float64       \n",
      " 27  skin                  53104 non-null  float64       \n",
      " 28  GENDER                53104 non-null  float64       \n",
      " 29  age                   53104 non-null  object        \n",
      " 30  ICU                   53104 non-null  float64       \n",
      " 31  NICU                  53104 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(23), object(8)\n",
      "memory usage: 13.4+ MB\n"
     ]
    }
   ],
   "source": [
    "features.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 42483 samples.\n",
      "Testing set has 10621 samples.\n"
     ]
    }
   ],
   "source": [
    "# Split into train 80% and test 20%\n",
    "X_train, X_test, y_train, y_test = train_test_split(features,\n",
    "                                                    LOS,\n",
    "                                                    test_size = .20,\n",
    "                                                    random_state = 0)\n",
    "\n",
    "# Show the results of the split\n",
    "print(\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "print(\"Testing set has {} samples.\".format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a real number, not 'Timestamp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_75961/708230068.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Instantiate and fit Regressor Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mreg_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mreg_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Make predictions with model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0my_test_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreg_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/health/lib/python3.12/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1469\u001b[0m                 skip_parameter_validation=(\n\u001b[1;32m   1470\u001b[0m                     \u001b[0mprefer_skip_nested_validation\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1472\u001b[0m             \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1473\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/health/lib/python3.12/site-packages/sklearn/linear_model/_stochastic_gradient.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[1;32m   1651\u001b[0m             \u001b[0mFitted\u001b[0m \u001b[0;34m`\u001b[0m\u001b[0mSGDRegressor\u001b[0m\u001b[0;34m`\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m         \"\"\"\n\u001b[1;32m   1653\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_more_validate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1655\u001b[0;31m         return self._fit(\n\u001b[0m\u001b[1;32m   1656\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1657\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1658\u001b[0m             \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/health/lib/python3.12/site-packages/sklearn/linear_model/_stochastic_gradient.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, alpha, C, loss, learning_rate, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[1;32m   1594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1595\u001b[0m         \u001b[0;31m# Clear iteration count for multiple call to fit.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1596\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1598\u001b[0;31m         self._partial_fit(\n\u001b[0m\u001b[1;32m   1599\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1601\u001b[0m             \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/health/lib/python3.12/site-packages/sklearn/linear_model/_stochastic_gradient.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, alpha, C, loss, learning_rate, max_iter, sample_weight, coef_init, intercept_init)\u001b[0m\n\u001b[1;32m   1472\u001b[0m         \u001b[0mcoef_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m         \u001b[0mintercept_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m     \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[0mfirst_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"coef_\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1476\u001b[0;31m         X, y = self._validate_data(\n\u001b[0m\u001b[1;32m   1477\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1478\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1479\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/health/lib/python3.12/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    646\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"estimator\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcheck_y_params\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m                     \u001b[0mcheck_y_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdefault_check_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/health/lib/python3.12/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1297\u001b[0m         raise ValueError(\n\u001b[1;32m   1298\u001b[0m             \u001b[0;34mf\"\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mestimator_name\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m requires y to be passed, but the target y is None\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m         \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1301\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m   1302\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/health/lib/python3.12/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1009\u001b[0m                         \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1014\u001b[0m                 raise ValueError(\n\u001b[1;32m   1015\u001b[0m                     \u001b[0;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m                 \u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/health/lib/python3.12/site-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0;31m# Use NumPy API to support order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m         \u001b[0;31m# container that is consistent with the input's namespace.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/health/lib/python3.12/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, dtype, copy)\u001b[0m\n\u001b[1;32m   2149\u001b[0m     def __array__(\n\u001b[1;32m   2150\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool_t\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2151\u001b[0m     \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2152\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2153\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2154\u001b[0m         if (\n\u001b[1;32m   2155\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2156\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a real number, not 'Timestamp'"
     ]
    }
   ],
   "source": [
    "# Regression models for comparison\n",
    "models = [SGDRegressor(random_state = 0),\n",
    "          GradientBoostingRegressor(random_state = 0),\n",
    "          LinearRegression(),\n",
    "          KNeighborsRegressor(),\n",
    "          RandomForestRegressor(random_state = 0)]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for model in models:\n",
    "\n",
    "    # Instantiate and fit Regressor Model\n",
    "    reg_model = model\n",
    "    reg_model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions with model\n",
    "    y_test_preds = reg_model.predict(X_test)\n",
    "\n",
    "    # Grab model name and store results associated with model\n",
    "    name = str(model).split(\"(\")[0]\n",
    "\n",
    "    results[name] = r2_score(y_test, y_test_preds)\n",
    "    print('{} done.'.format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "health",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
